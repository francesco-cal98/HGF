{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDM Example\n",
    "This example employs the model ddm_hgf. The first section simulates beliefs and responses of a putative agent.\n",
    "The second section shows the use of PAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies \n",
    "\n",
    "import numpy as np \n",
    "import HGF\n",
    "import pandas as pd\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importing HGF library\n",
    "import HGF.hgf_config\n",
    "import HGF.hgf_fit\n",
    "\n",
    "# Extracting the parent dir in order to append it to the python path \n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))  # Adjust if needed\n",
    "\n",
    "# Add it to the Python path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# importing dependencies \n",
    "from PAM.DDM.ddm_hgf_config import ddm_hgf_config\n",
    "from PAM.DDM.utl.scaled_sigmoid import scaled_sigmoid\n",
    "from PAM.DDM.utl.utl_wfpt import utl_wfpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trial list -- Specify the path -- \n",
    "u = pd.read_csv('u.csv')\n",
    "u = u.values\n",
    "u = u.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Simulate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored trials: []\n",
      "Irregular trials: []\n",
      "\n",
      "Initializing optimization run...\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 265.698074\n",
      "         Iterations: 6\n",
      "         Function evaluations: 21\n",
      "         Gradient evaluations: 7\n",
      "\n",
      "\n",
      "RESULTS:\n",
      "\n",
      "Parameter estimates - perceptual model:\n",
      " mu_0: \t [nan  0.  1.]\n",
      " sa_0: \t [nan 0.1 1. ]\n",
      " rho: \t [nan  0.  0.]\n",
      " ka: \t [1. 1.]\n",
      " om: \t [        nan -3.57818887]\n",
      " th: \t 0.6495383397499885\n",
      "\n",
      "MODEL QUALITY:\n",
      " LME: \t -265.41135491471664 \t\t (more is better)\n",
      " AIC: \t 528.1669974755891 \t\t (less is better)\n",
      " BIC: \t 534.7636322086852 \t\t (less is better)\n",
      "Ignored trials: []\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "\n",
    "om2 = -4 # learning rate\n",
    "a_a = 1.2 # boundary separation\n",
    "a_v = 2 # drift rate\n",
    "b_a = 0 # influence of beliefs on a\n",
    "b_w = 0.7 # influence of beliefs on w\n",
    "b_v = 0 # no influence of beliefs on v\n",
    "Ter = 0.15 # non-decision time\n",
    "\n",
    "# Simulate Beliefs\n",
    "bo = HGF.hgf_fit.fitModel([], u,HGF.hgf_config.ehgf_binary_config, HGF.hgf_config.bayes_optimal_binary_config)\n",
    "priormus = bo['p_prc']['p'] \n",
    "priormus[-2]=om2\n",
    "esim = HGF.hgf_sim.simModel(u,HGF.hgf.ehgf_binary,priormus)\n",
    "\n",
    "# Extract trial-wise beliefs about u\n",
    "muhat = esim['traj']['mu_hat'][:,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Simulate Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision and trial-wise absorbing barrier\n",
    "precision = scaled_sigmoid(1 / (muhat * (1 - muhat)) - 4, 1) - 0.5\n",
    "a = a_a + b_a * precision\n",
    "\n",
    "# Trial-wise starting point and drift rate\n",
    "w = 0.5 + b_w * (muhat - 0.5)\n",
    "v = u * (a_v + b_v * (muhat - 0.5)) - (1 - u) * (a_v + b_v * ((1 - muhat) - 0.5))\n",
    "\n",
    "# Initialize response times and responses\n",
    "rt = np.zeros(len(u))\n",
    "\n",
    "resp = np.zeros(len(u))\n",
    "\n",
    "# Simulate responses and response times\n",
    "for n in range(len(u)):\n",
    "    P1 = utl_wfpt(np.arange(0.001, 3, 0.001), -v[n], a[n], 1 - w[n])\n",
    "    P2 = utl_wfpt(np.arange(0.001, 3, 0.001), v[n], a[n], w[n])\n",
    "    \n",
    "    P = np.concatenate([P2[::-1], P1])\n",
    "    time_values = np.concatenate([-np.arange(0.001, 3, 0.001)[::-1], np.arange(0.001, 3, 0.001)])\n",
    "    \n",
    "    selected_time = np.random.choice(time_values, p=P / np.sum(P))\n",
    "    rt[n] = abs(selected_time)\n",
    "    resp[n] = 1 if selected_time > 0 else 0\n",
    "\n",
    "# Adjust response times by adding Ter\n",
    "rt += Ter\n",
    "y = np.column_stack((rt, resp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Fit DDM HGF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored trials: []\n",
      "Irregular trials: []\n",
      "\n",
      "Initializing optimization run...\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -189.563030\n",
      "         Iterations: 14\n",
      "         Function evaluations: 119\n",
      "         Gradient evaluations: 17\n",
      "\n",
      "\n",
      "RESULTS:\n",
      "\n",
      "Parameter estimates - perceptual model:\n",
      " mu_0: \t [nan  0.  1.]\n",
      " sa_0: \t [nan 0.1 1. ]\n",
      " rho: \t [nan  0.  0.]\n",
      " ka: \t [1. 1.]\n",
      " om: \t [        nan -2.59271641]\n",
      " th: \t 6.053663744150753\n",
      "\n",
      "Parameter estimates - observation model:\n",
      " a_a: \t 1.201866238958768\n",
      " a_v: \t 2.133789105036373\n",
      " b_w: \t 0.6693798316625874\n",
      " b_a: \t 0.0\n",
      " b_v: \t 0.0\n",
      " Ter: \t 0.15085920851999746\n",
      "\n",
      "MODEL QUALITY:\n",
      " LME: \t 181.10873183422106 \t\t (more is better)\n",
      " AIC: \t -387.6451419723989 \t\t (less is better)\n",
      " BIC: \t -387.9700776188333 \t\t (less is better)\n"
     ]
    }
   ],
   "source": [
    "# Configure Model\n",
    "overwrite_option_mus = {'c_prc' : {'om' : bo['p_prc']['om'] },'c_obs': {'b_asa': 0, 'b_vsa' : 0}}\n",
    "obs_model =  ddm_hgf_config\n",
    "\n",
    "# Combine rt and resp for the current subject\n",
    "y = np.column_stack((rt, resp))  \n",
    "\n",
    "# Fit the model \n",
    "m = HGF.hgf_fit.fitModel(y, u,HGF.hgf_config.ehgf_binary_config , obs_model, opt_model=HGF.hgf_config.quasinewton_optim_config,overwrite_opt=overwrite_option_mus)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
